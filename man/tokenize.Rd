% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/PsychWordVec.R
\name{tokenize}
\alias{tokenize}
\title{Tokenize raw texts for training word vectors.}
\usage{
tokenize(
  text,
  tokenizer = text2vec::word_tokenizer,
  split = " ",
  remove = "_|'\\\\w+|<br/>|<br />|e\\\\.g\\\\.|i\\\\.e\\\\.",
  simplify = TRUE
)
}
\arguments{
\item{text}{Character vector (strings).}

\item{tokenizer}{Function used to tokenize the text.
Defaults to \code{\link[text2vec:tokenizers]{text2vec::word_tokenizer}}.}

\item{split}{Separator between tokens, only used when \code{simplify=TRUE}.
Defaults to \code{" "}.}

\item{remove}{Strings (in regular expression) to be removed from the text.
Defaults to \code{"_|'\\\\w+|<br/>|<br />|e\\\\.g\\\\.|i\\\\.e\\\\."}.
You may turn off this by specifying \code{remove=NULL}.}

\item{simplify}{Return a character vector (\code{TRUE}) or a list of character vectors (\code{FALSE}).
Defaults to \code{TRUE}.}
}
\value{
\itemize{
  \item{\code{simplify=TRUE}: A tokenized character vector,
  with each element as a sentence.}
  \item{\code{simplify=FALSE}: A list of tokenized character vectors,
  with each element as a vector of tokens in a sentence.}
}
}
\description{
Tokenize raw texts for training word vectors.
}
\examples{
txt1 = c(
  "I love natural language processing (NLP)!",
  "I've been in this city for 10 years. I really like here!",
  "However, my computer is not among the \"Top 10\" list."
)
tokenize(txt1, simplify=FALSE)
tokenize(txt1) \%>\% cat(sep="\n----\n")

txt2 = text2vec::movie_review$review[1:5]
tokens = tokenize(txt2)

}
